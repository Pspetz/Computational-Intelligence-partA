{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:10:05.158849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 03:10:05.158874: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.metrics import accuracy_score2\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATA\n",
    "path = '/home/spetz/Downloads/DeliciousMIL/Data/train-data.dat'\n",
    "\n",
    "\n",
    "clean_files = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "file = open(path).readlines()\n",
    "len(file)\n",
    "\n",
    "\n",
    "clean_doc = []\n",
    "wordfreq = {}\n",
    "for doc in file:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    for token in tokens:\n",
    "        if token not in wordfreq.keys():\n",
    "            wordfreq[token] = 1\n",
    "        else:\n",
    "            wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()\n",
    "\n",
    "sentence_vectors = []\n",
    "for doc in file:\n",
    "    doc_tokens = nltk.word_tokenize(doc)\n",
    "    vec = []\n",
    "    for token in wordfreq:\n",
    "        if token in doc_tokens:\n",
    "            count = 0\n",
    "            for tok in doc_tokens:\n",
    "                if tok == token:\n",
    "                    count += 1\n",
    "            vec.append(count)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "    sentence_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST-DATA\n",
    "path = '/home/spetz/Downloads/DeliciousMIL/Data/test-data.dat'\n",
    "\n",
    "clean_files = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "file = open(path).readlines()\n",
    "len(file)\n",
    "\n",
    "clean_docc = []\n",
    "wordfreqq = {}\n",
    "for doc in file:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    for token in tokens:\n",
    "        if token not in wordfreqq.keys():\n",
    "            wordfreqq[token] = 1\n",
    "        else:\n",
    "            wordfreqq[token] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist()\n",
    "sentence_vectorss = []\n",
    "for doc in file:\n",
    "    doc_tokens = nltk.word_tokenize(doc)\n",
    "    vecc = []\n",
    "    for token in wordfreqq:\n",
    "        if token in doc_tokens:\n",
    "            count = 0\n",
    "            for tok in doc_tokens:\n",
    "                if tok == token:\n",
    "                    count += 1\n",
    "            vecc.append(count)\n",
    "        else:\n",
    "            vecc.append(0)\n",
    "    sentence_vectorss.append(vecc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3983, 8202) (3983, 8202) (3983, 20) (3983, 20)\n"
     ]
    }
   ],
   "source": [
    "#same length lists\n",
    "#X_train = pad_sequences(sentence_vectors , padding = 'post',maxlen=20,dtype='float32')\n",
    "#X_test = pad_sequences(sentence_vectorss , padding = 'post',maxlen=20 ,dtype='float32')\n",
    "#np\n",
    "#train_data\n",
    "x=sentence_vectors[:3983]\n",
    "X_train =np.array(x)\n",
    "#test data\n",
    "X_test =np.array(sentence_vectorss)\n",
    "\n",
    "#morfopoihsh \n",
    "X_train=X_train[:, :-320]\n",
    "X_test=X_test[:, :-1]\n",
    "\n",
    "#load labels\n",
    "labels_fnames = [\n",
    "            '/home/spetz/Downloads/DeliciousMIL/Data/train-label.dat',\n",
    "            '/home/spetz/Downloads/DeliciousMIL/Data/test-label.dat'\n",
    "            ]\n",
    "\n",
    "Y_train = pd.read_csv(labels_fnames[0], nrows=3983 , delimiter = ' ', header = None)\n",
    "Y_test= pd.read_csv(labels_fnames[1], delimiter = ' ', header = None)\n",
    "\n",
    "\n",
    "#len(test_labels) 3983\n",
    "#len(train_labels) 8251\n",
    "#one- hot -encoding\n",
    "#Y_train = tf.keras.utils.to_categorical(Y_train,20 )\n",
    "#Y_test = tf.keras.utils.to_categorical(Y_test,20 )\n",
    "\n",
    "def preprocessing(X_train,Y_train,X_test,Y_test,type=\"Normalization\"):\n",
    "\n",
    "            #NORMALIZATION#\n",
    "    if type == \"Normalization\":\n",
    "        X_train_normalized = tf.keras.utils.normalize(X_train)\n",
    "        X_test_normalized = tf.keras.utils.normalize(X_test)\n",
    "        return X_train_normalized,Y_train,X_test_normalized,Y_test\n",
    "\n",
    "            #STANDARDIZED#\n",
    "    elif type == \"Standardized\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train_Standardized =scaler.fit_transform(X_train)\n",
    "        X_test_Standardized=scaler.fit_transform(X_test)\n",
    "        return X_train_Standardized,Y_train,X_test_Standardized,Y_test\n",
    "            #NORM-WITH MINMAX#\n",
    "    elif type == \"MinMax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_minmax = scaler.fit_transform(X_train)\n",
    "        X_test_minmax = scaler.fit_transform(X_test)\n",
    "        return X_train_minmax , Y_train ,X_test_minmax ,Y_test\n",
    "\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.optimizer_v1 import SGD\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    r=0.5\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(Dense(2002, activation='relu', input_shape=(3983,) ,kernel_regularizer=tf.keras.regularizers.L2( l2=r)))\n",
    "    model.add(Dense(2002, activation='relu',kernel_regularizer=tf.keras.regularizers.L2( l2=r)))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "    # optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1,momentum = 0.6)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model \n",
    "def create_model_mse():\n",
    "    r=0.5\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(Dense(2002, activation='relu', input_shape=(3983,),kernel_regularizer=tf.keras.regularizers.L2( l2=r)))\n",
    "    model.add(Dense(2002, activation='relu', kernel_regularizer=tf.keras.regularizers.L2( l2=r)))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "    # optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum = 0.6)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def evaluate_model(X_train_normalized,Y_train,X_test_normalized,Y_test):            \n",
    "    fold_number2=0\n",
    "    fold_number = 0\n",
    "    sum_of_acc2 =0\n",
    "    sum_of_loss2 = 0\n",
    "    sum_of_acc=0\n",
    "    sum_of_loss=0\n",
    "    losses,scores,histories = list(),list(),list()\n",
    "    losses2,scores2,histories2 = list(),list(),list()\n",
    "    kfold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "    epochs = 10\n",
    "    for train_index, test_index in kfold.split(X_train_normalized,Y_train):  \n",
    "        shallow_mlp_model = create_model()\n",
    "        mse_model = create_model_mse()\n",
    "        #es=EarlyStopping(monitor='val_loss' , mode='min' , verbose=1) \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_train_normalized[train_index,:], X_train_normalized[test_index,:]\n",
    "        y_train, y_test = Y_train.iloc[train_index],Y_train.iloc[test_index]\n",
    "    \n",
    "        callback =EarlyStopping(monitor='val_accuracy' , mode=\"max\" , min_delta=0 , patience=5 , verbose=1)\n",
    "        #MODEL for cross-entropy\n",
    "\n",
    "        history = shallow_mlp_model.fit(X_train_normalized[train_index,:],Y_train.iloc[train_index] , epochs=epochs , validation_data=(X_test, y_test) ,callbacks=[callback],verbose=1)\n",
    "        loss, val_acc = shallow_mlp_model.evaluate(X_test_normalized,Y_test,verbose=1)\n",
    "        #MODEL 2 for Mse\n",
    "       \n",
    "        history2 = mse_model.fit(X_train_normalized[train_index,:],Y_train.iloc[train_index] , epochs=epochs , validation_data=(X_test, y_test) ,callbacks=[callback] ,verbose=1)\n",
    "        loss2, val_acc2 = mse_model.evaluate(X_test_normalized,Y_test,verbose=1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        ###########################\n",
    "        fold_number +=1 \n",
    "        fold_number2 +=1\n",
    "        ##########################\n",
    "        print(\" for cross entropy fold\",(fold_number),\"\\n|  loss:\" , loss, \"Accuracy:\",val_acc)\n",
    "        print(\" for Mse fold\",(fold_number2),\"\\n|  loss:\" , loss2, \"Accuracy:\",val_acc2)\n",
    "        ##########################\n",
    "        sum_of_acc += val_acc\n",
    "        sum_of_loss += loss\n",
    "        #########################\n",
    "        sum_of_loss2 +=loss2\n",
    "        sum_of_acc2 += val_acc2\n",
    "\n",
    "        scores.append(val_acc)\n",
    "        histories.append(history)\n",
    "        scores2.append(val_acc2)\n",
    "        histories2.append(history2)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"\\n Cross-Entropy:the average of the loss and acc is: \\n\",\"loss:\" , sum_of_loss/fold_number, \"\\n\" , \"Accuracy\" , sum_of_acc/fold_number,\"\\n\")\n",
    "        print(\"\\n MSE:the average of the lose and acc is: \\n\",\"loss:\" , sum_of_loss2/fold_number2, \"\\n\" , \"Accuracy\" , sum_of_acc2/fold_number2,\"\\n\")\n",
    "        \n",
    "    return history,history2\n",
    "\n",
    "\n",
    "    \n",
    "def create_model_plots(history,history2):\n",
    "        plt.figure(0)\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Accuracy (train)')\n",
    "        plt.plot(history.history['val_accuracy'], label='Accuracy (test)')\n",
    "        plt.title(\"Accuracy with Cross Entropy loss\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history2.history['accuracy'], label='Accuracy (train)')\n",
    "        plt.plot(history2.history['val_accuracy'], label='Accuracy (test)')\n",
    "        plt.title(\"Accuracy with MSE loss\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # plot the cross entropy loss\n",
    "        plt.figure(1)\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Cross entropy (train)')\n",
    "        plt.plot(history.history['val_loss'], label='Cross entropy (test)')\n",
    "        plt.title('Cross Entropy Evaluated')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Error value')\n",
    "        plt.legend()\n",
    "\n",
    "    # plot the mse loss\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history2.history['loss'], label='MSE (train)')\n",
    "        plt.plot(history2.history['val_loss'], label='MSE (test)')\n",
    "\n",
    "        plt.title('MSE Evaluated')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Error value')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:13:21.136083: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-26 03:13:21.136162: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (spetz-ZenBook-UX434IQ-Q407IQ): /proc/driver/nvidia/version does not exist\n",
      "2022-04-26 03:13:21.138309: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 80.0429 - accuracy: 0.2329 - val_loss: 0.4334 - val_accuracy: 0.2409\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.3989 - accuracy: 0.2398 - val_loss: 0.3870 - val_accuracy: 0.2409\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.3844 - accuracy: 0.2398 - val_loss: 0.3851 - val_accuracy: 0.2409\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3835 - accuracy: 0.2398 - val_loss: 0.3849 - val_accuracy: 0.2409\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3833 - accuracy: 0.2398 - val_loss: 0.3849 - val_accuracy: 0.2409\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.3832 - accuracy: 0.2398 - val_loss: 0.3849 - val_accuracy: 0.2409\n",
      "Epoch 6: early stopping\n",
      "  5/125 [>.............................] - ETA: 3s - loss: 0.3884 - accuracy: 0.2750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:14:33.915522: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 130674264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 29ms/step - loss: 0.3865 - accuracy: 0.2583\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 79.6209 - accuracy: 0.2250 - val_loss: 0.1317 - val_accuracy: 0.2409\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1315 - accuracy: 0.2398 - val_loss: 0.1316 - val_accuracy: 0.2409\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1313 - accuracy: 0.2398 - val_loss: 0.1314 - val_accuracy: 0.2409\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.1311 - accuracy: 0.2398 - val_loss: 0.1312 - val_accuracy: 0.2409\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.1309 - accuracy: 0.2398 - val_loss: 0.1310 - val_accuracy: 0.2409\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.1306 - accuracy: 0.2398 - val_loss: 0.1307 - val_accuracy: 0.2409\n",
      "Epoch 6: early stopping\n",
      "  5/125 [>.............................] - ETA: 3s - loss: 0.1289 - accuracy: 0.2750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:15:52.256482: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 130674264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 34ms/step - loss: 0.1321 - accuracy: 0.2583\n",
      "--------------------------------------------------------------------------------\n",
      " for cross entropy fold 1 \n",
      "|  loss: 0.3865349292755127 Accuracy: 0.2583479881286621\n",
      " for Mse fold 1 \n",
      "|  loss: 0.13212083280086517 Accuracy: 0.2583479881286621\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Cross-Entropy:the average of the loss and acc is: \n",
      " loss: 0.3865349292755127 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "\n",
      " MSE:the average of the lose and acc is: \n",
      " loss: 0.13212083280086517 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 16s 129ms/step - loss: 80.0611 - accuracy: 0.2348 - val_loss: 0.4337 - val_accuracy: 0.2384\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.3988 - accuracy: 0.2404 - val_loss: 0.3875 - val_accuracy: 0.2384\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.3844 - accuracy: 0.2404 - val_loss: 0.3853 - val_accuracy: 0.2384\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.3835 - accuracy: 0.2404 - val_loss: 0.3850 - val_accuracy: 0.2384\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.3833 - accuracy: 0.2404 - val_loss: 0.3849 - val_accuracy: 0.2384\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.3833 - accuracy: 0.2404 - val_loss: 0.3849 - val_accuracy: 0.2384\n",
      "Epoch 6: early stopping\n",
      "  5/125 [>.............................] - ETA: 3s - loss: 0.3881 - accuracy: 0.2750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:17:15.621769: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 130674264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 30ms/step - loss: 0.3866 - accuracy: 0.2583\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 13s 124ms/step - loss: 79.6244 - accuracy: 0.2285 - val_loss: 0.1329 - val_accuracy: 0.2384\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1312 - accuracy: 0.2404 - val_loss: 0.1327 - val_accuracy: 0.2384\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1310 - accuracy: 0.2404 - val_loss: 0.1325 - val_accuracy: 0.2384\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1308 - accuracy: 0.2404 - val_loss: 0.1323 - val_accuracy: 0.2384\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.1306 - accuracy: 0.2404 - val_loss: 0.1320 - val_accuracy: 0.2384\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1304 - accuracy: 0.2404 - val_loss: 0.1318 - val_accuracy: 0.2384\n",
      "Epoch 6: early stopping\n",
      "  5/125 [>.............................] - ETA: 3s - loss: 0.1289 - accuracy: 0.2750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:18:34.523325: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 130674264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 31ms/step - loss: 0.1321 - accuracy: 0.2583\n",
      "--------------------------------------------------------------------------------\n",
      " for cross entropy fold 2 \n",
      "|  loss: 0.38657018542289734 Accuracy: 0.2583479881286621\n",
      " for Mse fold 2 \n",
      "|  loss: 0.13211603462696075 Accuracy: 0.2583479881286621\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Cross-Entropy:the average of the loss and acc is: \n",
      " loss: 0.386552557349205 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "\n",
      " MSE:the average of the lose and acc is: \n",
      " loss: 0.13211843371391296 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 13s 124ms/step - loss: 80.0438 - accuracy: 0.2360 - val_loss: 0.4399 - val_accuracy: 0.2208\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4027 - accuracy: 0.2448 - val_loss: 0.3845 - val_accuracy: 0.2208\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.3855 - accuracy: 0.2448 - val_loss: 0.3816 - val_accuracy: 0.2208\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.3844 - accuracy: 0.2448 - val_loss: 0.3814 - val_accuracy: 0.2208\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.3843 - accuracy: 0.2448 - val_loss: 0.3813 - val_accuracy: 0.2208\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.3842 - accuracy: 0.2448 - val_loss: 0.3811 - val_accuracy: 0.2208\n",
      "Epoch 6: early stopping\n",
      "  3/125 [..............................] - ETA: 4s - loss: 0.3898 - accuracy: 0.2708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 03:20:02.975090: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 130674264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 36ms/step - loss: 0.3865 - accuracy: 0.2583\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 79.6330 - accuracy: 0.2414 - val_loss: 0.1297 - val_accuracy: 0.2208\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.1320 - accuracy: 0.2448 - val_loss: 0.1295 - val_accuracy: 0.2208\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.1318 - accuracy: 0.2448 - val_loss: 0.1293 - val_accuracy: 0.2208\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.1316 - accuracy: 0.2448 - val_loss: 0.1291 - val_accuracy: 0.2208\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.1314 - accuracy: 0.2448 - val_loss: 0.1289 - val_accuracy: 0.2208\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.1312 - accuracy: 0.2448 - val_loss: 0.1287 - val_accuracy: 0.2208\n",
      "Epoch 6: early stopping\n",
      "125/125 [==============================] - 5s 36ms/step - loss: 0.1321 - accuracy: 0.2583\n",
      "--------------------------------------------------------------------------------\n",
      " for cross entropy fold 3 \n",
      "|  loss: 0.3865421414375305 Accuracy: 0.2583479881286621\n",
      " for Mse fold 3 \n",
      "|  loss: 0.1321200430393219 Accuracy: 0.2583479881286621\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Cross-Entropy:the average of the loss and acc is: \n",
      " loss: 0.38654908537864685 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "\n",
      " MSE:the average of the lose and acc is: \n",
      " loss: 0.13211897015571594 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 80.0645 - accuracy: 0.2300 - val_loss: 0.4323 - val_accuracy: 0.2575\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.4009 - accuracy: 0.2356 - val_loss: 0.3813 - val_accuracy: 0.2575\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.3860 - accuracy: 0.2356 - val_loss: 0.3786 - val_accuracy: 0.2575\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 0.3851 - accuracy: 0.2356 - val_loss: 0.3781 - val_accuracy: 0.2575\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.3850 - accuracy: 0.2356 - val_loss: 0.3782 - val_accuracy: 0.2575\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 0.3850 - accuracy: 0.2356 - val_loss: 0.3780 - val_accuracy: 0.2575\n",
      "Epoch 6: early stopping\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.3865 - accuracy: 0.2583\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 79.5958 - accuracy: 0.2322 - val_loss: 0.1296 - val_accuracy: 0.2575\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.1320 - accuracy: 0.2356 - val_loss: 0.1294 - val_accuracy: 0.2575\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.1318 - accuracy: 0.2356 - val_loss: 0.1292 - val_accuracy: 0.2575\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.1316 - accuracy: 0.2356 - val_loss: 0.1290 - val_accuracy: 0.2575\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.1314 - accuracy: 0.2356 - val_loss: 0.1288 - val_accuracy: 0.2575\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.1312 - accuracy: 0.2356 - val_loss: 0.1286 - val_accuracy: 0.2575\n",
      "Epoch 6: early stopping\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.1321 - accuracy: 0.2583\n",
      "--------------------------------------------------------------------------------\n",
      " for cross entropy fold 4 \n",
      "|  loss: 0.3865368366241455 Accuracy: 0.2583479881286621\n",
      " for Mse fold 4 \n",
      "|  loss: 0.1321033239364624 Accuracy: 0.2583479881286621\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Cross-Entropy:the average of the loss and acc is: \n",
      " loss: 0.3865460231900215 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "\n",
      " MSE:the average of the lose and acc is: \n",
      " loss: 0.13211505860090256 \n",
      " Accuracy 0.2583479881286621 \n",
      "\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 80.0587 - accuracy: 0.2372 - val_loss: 0.4397 - val_accuracy: 0.2425\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 0.3992 - accuracy: 0.2394 - val_loss: 0.3915 - val_accuracy: 0.2425\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.3834 - accuracy: 0.2394 - val_loss: 0.3896 - val_accuracy: 0.2425\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.3824 - accuracy: 0.2394 - val_loss: 0.3894 - val_accuracy: 0.2425\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.3822 - accuracy: 0.2394 - val_loss: 0.3892 - val_accuracy: 0.2425\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.3822 - accuracy: 0.2394 - val_loss: 0.3892 - val_accuracy: 0.2425\n",
      "Epoch 6: early stopping\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.3866 - accuracy: 0.2583\n",
      "Epoch 1/10\n",
      " 30/100 [========>.....................] - ETA: 19s - loss: 263.9760 - accuracy: 0.1917"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/spetz/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "def run_test():\n",
    "   x_train,y_train,x_test,y_test=preprocessing(X_train,Y_train,X_test,Y_test,type=\"MinMax\")\n",
    "   h1,h2 = evaluate_model(x_train,y_train,x_test,y_test)\n",
    "   create_model_plots(h1,h2)\n",
    "run_test()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
